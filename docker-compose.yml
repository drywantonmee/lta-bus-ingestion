version: '3.8'

x-airflow-common:
  &airflow-common
  build:
    context: .
    dockerfile: ./airflow/Dockerfile
  environment:
    &airflow-common-env
    AIRFLOW_HOME: ${AIRFLOW_HOME}
    AIRFLOW_UID: ${AIRFLOW_UID}
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__LOAD_DAGS_IN_WEBSERVER: 'true'
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@postgres:5432/${POSTGRES_DB}
    AIRFLOW__CORE__FERNET_KEY: '' # You should generate a proper Fernet key for production
    AIRFLOW__WEBSERVER__WEB_SERVER_PORT: 8080
    LTA_API_KEY: ${LTA_API_KEY}
    POSTGRES_HOST: ${POSTGRES_HOST}
    POSTGRES_PORT: ${POSTGRES_PORT}
    DB_USER: ${DB_USER}
    DB_PASSWORD: ${DB_PASSWORD}
    POSTGRES_DB: ${POSTGRES_DB}
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./data:/opt/airflow/data
    - ./jars:/opt/airflow/jars
    - ./scripts:/opt/airflow/scripts
    - ./config:/opt/airflow/config
    - ./artifacts:/opt/airflow/artifacts
    - ./LTA_DataMall_API_User_Guide.pdf:/opt/airflow/LTA_DataMall_API_User_Guide.pdf
    - ./README.md:/opt/airflow/README.md
    - ./requirements.txt:/opt/airflow/requirements.txt
  depends_on:
    postgres:
      condition: service_healthy
  networks:
    - lta-bus-data-network

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - lta-bus-data-network

  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    entrypoint: ["/bin/bash", "-c", "airflow db migrate && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com"]
    healthcheck:
      test: ["CMD-SHELL", "airflow db check"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: "no"

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow-webserver
    command: webserver
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 30s
      retries: 3
    restart: always

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    command: scheduler
    restart: always

  airflow-worker:
    <<: *airflow-common
    container_name: airflow-worker
    command: worker
    restart: always

  spark-master:
    image: bitnami/spark:3.5.1
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      SPARK_MASTER_PORT: ${SPARK_MASTER_PORT}
      SPARK_MASTER_WEBUI_PORT: ${SPARK_UI_PORT}
    ports:
      - "${SPARK_MASTER_PORT}:${SPARK_MASTER_PORT}"
      - "${SPARK_UI_PORT}:${SPARK_UI_PORT}"
    networks:
      - lta-bus-data-network

  spark-worker:
    image: bitnami/spark:3.5.1
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:${SPARK_MASTER_PORT}
      SPARK_WORKER_PORT: ${SPARK_WORKER_PORT}
      SPARK_WORKER_WEBUI_PORT: ${SPARK_WORKER_UI_PORT}
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
    ports:
      - "${SPARK_WORKER_PORT}:${SPARK_WORKER_PORT}"
      - "${SPARK_WORKER_UI_PORT}:${SPARK_WORKER_UI_PORT}"
    networks:
      - lta-bus-data-network

volumes:
  postgres_data:

networks:
  lta-bus-data-network:
    driver: bridge
